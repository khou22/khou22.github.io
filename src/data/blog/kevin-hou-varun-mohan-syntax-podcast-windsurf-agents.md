---
title: "Syntax Podcast: Windsurf forked VS Code to compete with Cursor. Talking the future of AI + Coding"
author: "Kevin Hou, Varun Mohan, and Syntax Team"
date: 2025-01-22 9:00:00
description: "Varun Mohan and I were invited onto the Syntax Podcast to discuss the Windsurf Editor, the first AI agent-powered code editor. We also talked about its origin story, the benefits of agentic superpowers, technical challengs, and much more."
image: "https://khou22.github.io/media/blog/images/syntax-podcast-windsurf-editor-cover.jpg"
tags: [coding]
featured: false
---

Varun Mohan and I were invited onto the Syntax Podcast to discuss the Windsurf Editor, the first AI agent-powered code editor. We also talked about its origin story, the benefits of agentic superpowers, technical challengs, and much more.

I've been lucky enough to be on the Syntax Podcast twice now! The hosts, Scott and Wes, are incrediblely good at their craft and it's always a pleasure chatting with them about tech, AI, and life in general.

Check out the episode here: [https://syntax.fm/show/870/windsurf-forked-vs-code-to-compete-with-cursor-talking-the-future-of-ai-coding](https://syntax.fm/show/870/windsurf-forked-vs-code-to-compete-with-cursor-talking-the-future-of-ai-coding).

[![syntax podcast cover photo](https://khou22.github.io/media/blog/images/syntax-podcast-windsurf-editor-cover.jpg)](https://syntax.fm/show/870/windsurf-forked-vs-code-to-compete-with-cursor-talking-the-future-of-ai-coding)

## Full Transcript

> Welcome to Syntax Today. We have Kevin and Varun on from Windsurf. And we're here to talk today about AI and coding. And there's a lot going on in this space right now. Is it going to replace developers entirely? Is this a tool that you should be using? Can you trust the code that it's cranking out? There's just so much going on. And we thought, like, let's have them on to just talk about, obviously, we're going to talk about Windsurf and the editor that they forked VS code, right? And we're going to talk about that and how it compares to Copilot and cursor and all that. But also, I'm more interested in just like, talking about like, what is the state of web development look like with all these crazy AI advancements in the last couple of years, even feels like the last six months, everything has really cranked up as well. So welcome, Kevin and Varun. Thanks for coming on. Thanks for having us. Yeah, good to be I guess, this is my second time on the podcast. So thank you for having me back. And then yeah, debut. Yep. You want to give us a quick rundown of who you are and what you do and kind of place what Windsurf is in relation to Codium? Yeah, happy to do that. So I'm Varun. I'm the CEO and co-founder of the company. If we go really, really back, so close to four years ago, the company actually started as a GPU virtualization company. So we built software to make GPU infrastructure really, really efficient. We even built compiler software for that. The middle of 2022 rolled around and we saw that generative AI was going to be huge for deep learning, right? We thought all the deep learning workloads were fundamentally going to be generative AI workloads. And in that world, we were early adopters of GitHub Copilot. And we thought building an application would be really exciting for us to take our infrastructure and go ahead and build an application. And we built up Codium for that reason. And Codium started out as purely an AI autocomplete tool. We provided it for free. Codium, the product is still entirely for free. But the trade-off we made was we were an extension in every single ID. That means VS Code, IntelliJ, PyCharm, Eclipse, Visual Studio, you name it, we had support in there. And we worked with some of the largest companies out there to not only deploy the product internally in their firewall, but also personalize the results to the private data inside the company. Our goal here was, hey, look, these models can generate sort of generic suggestions, but what happens if we could sort of do it in a way that was more personalized? And we actually trained and ran our own models to actually go ahead and do that. And just to skip to where we are now, what we felt was a couple months ago is that we felt that, hey, we could build a premier experience. And we were getting limited by what the ID fundamentally had by being a VS Code extension, potentially a JetBrains extension. We wanted to make a premier sort of experience, especially given where we think AI is going and how the way IDs are going to get used are going to fundamentally change. And happy to talk about that a little bit more. And that's why we launched Windsurf, actually, in the last two months. Yeah, you know what I've always appreciated about Codium in the past was just how fast it was. And it had like a definite eye towards general user experience. So when Windsurf was announced, it's not surprising that the focus is maybe on rethinking user experience a bit more in this space. Has that always been like forethought for you guys to say, user experience in these tools needs rethinking? Because, you know, sometimes they can just feel slapped on, or we're either adapting our coding tools towards how the LLMs work, or we're just shoving them into the editors, right? Yeah, completely. I think that's one of the primary motivations for doing the fork. It felt like the generative AI coding space was changing, at least the models and the intelligence were just getting better. But the user experience wasn't able to kind of meet the power of the LLMs. I mean, you had examples of people just generating code, you know, it's brilliant code in Sonnet or in chat GPT. And then now you've got this gap right between the browser and the editor. Like we really had to figure out how those two things could live together in harmony. Yeah. So thinking about like one a good example of this is if you've used Windsurf, we have that cascade action bar. So it's kind of like you can step through files, it's almost like a merge conflict resolver, right? You're saying, oh, I have these changes from the AI, I have my own changes, I want to review, kind of step through those changes and accept and reject the ones that I want. Those are examples of patterns that would feel are kind of impossible, or would be possible, but feel really bad if you were an extension, because it doesn't feel native to the experience. And so that's, you hit on a good point, which is user experience is kind of king. Yeah. And I guess maybe to add one more thing to that, we're not a company that's like, hey, these things are completely going to replace engineers. Because if we design the product to be like that, it would just be this blob that ran asynchronously. And just you kind of look at the response afterwards, we really care about the human AI sort of interaction paradigm, right? Like that's what autocomplete was in the very beginning. And right now, I guess the hard part about the paradigm is the AI is writing more and more of the software. So actually, the role of the way the human and AI sort of interact is fundamentally changing. And to that, we needed to go out and build a new interface. Oh, yeah. Yeah, it makes sense that it's kind of we're even laughing is the reason we initially switched to VS Code was because VS Code provided a much more rich UI for the different types of things. There's autocomplete, there's suggestions, there's tooltips, and you hover over top, there's sidebars and things like that. And then as we get into figuring out what does software development look like as people, we sort of wonder, do we need a different UI? Is the code editor even the right UI for this type of thing? So I have to ask is, obviously, Microsoft has their own dog in this race as well. Are they just moving too slow? Or do they not open up certain parts of it? They eventually are probably, they're already implementing a lot of these features as well. Do you see a future where VS Code also has this? Yeah, I think the way I sort of think about it, and the team sort of thought about it is, I think that the limit for software in general, like in theory, sort of they could have anything in the future. I think like that's objectively true. I guess the problem for us is like, if we have to build a great experience, and we are limited by whatever timeline that they have, yeah, it kind of means that, hey, we can't tell our users, hey, we're smart, and our product is great. And then meanwhile, people don't want to use it. I'll give you maybe a simple example of this, truly, truly simple example. And this is not even has anything to do with Cascade, which is the agent-like part of the product. So we have this feature called super complete. And the idea of super complete is it's the next rendition of autocomplete, which actually does next intent prediction. As you're writing code, it also refactors code for you. And the way we actually ended up building that was for VS Code, because they didn't let us provide a edit sort of functionality, a passive edit functionality, we needed to go out and dynamically generate PMGs and stick them on the side and show them on the side. And by the way, they were hard to get aligned given what the font size was. And we actually noticed the moment we implemented it natively in WinServe, the acceptance rate went up by multiple factors. Same exact product, right? And I guess the fundamental reason is because what we think is valuable to the end user may be different than what Microsoft thinks is valuable to the end user. They might think actually putting a lot of tool tips in GitHub is valuable and putting a lot of things in VS Code is not as valuable, but that ends up indirectly hurting us, right? If that's the case. So I think we started from what is the best possible experience we could build? And we were constantly realizing that we were fighting against what was accessible in VS Code. And it was not even just because they made proposed APIs that no one else can access. They also did that. But on top of that, they just didn't have a lot of functionality that we really wanted. So I think maybe the way I sort of look at it is every editor wins because of some disruption that's happening in the market, right? Like why did VS Code win? It won because TypeScript became popular. And then also you were able to build this very clean sort of ID experience on top of that, and then a very good extension framework that enabled a single ID to handle a bunch of different languages instead of JetBrains where everything, every language has its own ID, right? So you have this unified view. And I think now with AI, there's going to be a better ceiling on what's possible. And we want to hit that ceiling, I guess, is like the rough take we had. Totally. Yeah, that UI matters a lot too, because I find myself like over the last six months of when I asked AI to do too much, I would sort of get overwhelmed and just be like, I don't know, and then close it, you know? And I found myself as the UIs get better, allowing it to do a lot more. And a lot of that has to do with like how it's actually presented to you. And that's actually kind of a funny thing as well, because, and maybe we can get into this, is how you provide context to the model is extremely important. Like we had Kevin on, I don't know, like probably a year ago, and he was talking to us and we're like, hey, like you're using the models that everybody else is using. And he's like, it's not just about the model, like we can train models and whatnot. But what's really important is about the context that you provide to it, you know? Like what pieces of information are you giving it so that it can provide you the best possible output? So I kind of want to like go in that direction is like, how do you make the best possible completion or generation? You say, all right, make a new file that is a component and do X, Y, and Z. How does it know that I'm using React? How does it know to use specific camel casing and all those things that I, the way I code? Yeah, I think the paradigm shift with Windsurf was, so I remember having this conversation with you. And it was a lot of fun to think about and kind of audit all the areas of context that we were pulling. And I think back then, you know, we were looking at your files, we were looking at some remote repositories.
> But we've kind of paradigm shifted the way that we're thinking about that because Windsurf is inherently like an agentic editor. So what that basically means is the way that we retrieve context is as if a human would kind of retrieve context. So if you think at the core of the editor, there is this sort of agentic like entity that is like, okay, Wes wants to implement a new signup form. What are the things needed for the signup form? You know, you're going to start crawling your code base as if a new, let's just say a junior editor or junior developer just onboarded onto your team. They would go, they would read the documentation. They might go and look at some examples of past PRs or examples of files that already do this. They'll look at some configurations. They'll be reading, they'll be searching and grepping. And so this is the way that sort of humans kind of digest information. And in that way, we wanted to model how Windsurf would interpret and retrieve information similarly. So when you make that request, it decides kind of a plan of action. It is not just pulling everything all at once and then just hoping, fingers crossed, like, I have a million lines of code. Let me just resolve this into the solution. It's like, okay, no, first I'm going to go look at examples. I'm going to go look at your design system. I'll go look at your Tailwind config. Okay, I think I have enough information now. I'm going to start generating and it'll do it in piecemeal. Think of it as a human. You might set up your validation library first before you set up your, I don't know, your post requests. And in this way, you're kind of stepping through the solution as opposed to just, all right, context, retrieve, dump. And so it's a bit of a different pattern. So when you say agentic, just for the audience, I know you did explain it a bit there, but just to be super clear, like, it's using the concept of agents, which are, they're going off and executing tasks without you, right? So that's what you mean by that is like, the editor itself is executing tasks like a human would behind the scenes. That's what you're saying? Yes, more or less. So when you think, and if you use the Cascade sidebar, and so if you really see what that kind of means, so we can run terminal commands on behalf of the user inside of their kind of like file system. So if you want to push a repository, right, it would say, oh, okay, how would I push this code to a repo? All right, I'm going to use these git commands. I'm actually going to execute that on your behalf. It'll read files. It'll read from the internet. So it'll pull links and try and resolve those links. So it is behaving as if it has kind of like tools at its disposal to step through and kind of action by action, figure out what to do next. Yeah, sick. I think one of the maybe super quick things that we had when it came to like what we wanted to get out of these products is we think basically there's like a graduation happening in terms of the capabilities of these products, which is that, you know, in the past, like these tools, you would not mention a bunch of things, right? You'd be like, hey, build me a button that looks like at this. At that and at that. And we think that that is like what Google looked like in maybe 1999 or 2000, where you would actually tell it an and or of a bunch of queries. And then you would also say what site to get the result from. And we think that that is basically something that we think is an anti-pattern. We think what should probably be the case is you will write natural language. It should go out and do agentic retrieval. And we should actually be building out really good retrieval systems, which happy to talk about a little bit more to make it so that the user doesn't need to add a bunch of things and it can actually understand the intent of the very deep level. Yep. Yeah, let's talk about that. Because that's super interesting to me, because like the steps of become using AI is like, oh, I use the tab thing. And then, oh, yeah, maybe I'll highlight some text and ask it to fix something. And then, ooh, there's this sidebar where I can ask it to do multiple things, create multiple files, edit all these things, you know, like what I've been doing a lot lately is, yeah, like doing that tagging, you know, like put these files into context. But you're saying that eventually, we just won't need to do that. Like it would just be like a Google search where I just know what we want. How do you how do you do that? Actually, most of the people at our company don't mention anything, right? Like you should be able to use the fact that if you name a particular part of the repository with either clever indexing or the fact that we have good retrieval. Some of our retrieval techniques are pretty, pretty high powered. It actually goes through your entire code base with an LLM and chunks it up and then validates what sections are the best. Should be able to find the best snippets that you should be operating on top of, kind of like the way Kevin said, right? Like if you want to install a package, you shouldn't tell it where the installation file is. Actually, you should probably be able to find out where the installation packages run it for you and then deploy the app for you. Or if you think about a page in Next.js, if you're looking at a contact page, we can resolve the fact that it's page.tsx inside of, you know, probably slash contact. And if you think about the way the human would resolve this sort of query, they would probably command shift F and VS code, and they'd grab for contact and look for files that are named kind of loosely to that. And so this is sort of what we're doing behind the scenes. It's not you don't need to explicitly link the file that you're referencing. It's just they don't kind of figure it out. I know what a lot of other editor and copilot on VS code just added this cursor has this, this idea of like a rules file or a like a code base code style file. Does Windsurf have an equivalent of that? Or is what you're doing behind the scenes take the place of something like that? So we actually do have a kind of a rules approach. We actually call it this idea of memories, which is this idea of you could actually have provide the system with some four memories. We're very soon going to launch this approach of memories actually being dynamic. So the AI itself can write new memories. So it's not just things that the user writes themselves. But the main reason why you would want to use something like that, and this is actually just valuable to have this idea of a rule is, let's say I write a different language, or like I'm a person that's fluent in Turkish. I probably want the AI to be talking to me in Turkish. And hopefully every time I don't need to tell it, talk to me in Turkish, right? Like that's a waste of time. Or if it talks to me in English every time. So for those things, yeah, we do have the ability to have these global rule sets on how you like to build apps internally. And we think that that's generally useful, because it just reduces the number of like boilerplate messages that you need to send to the AI, which is which is a good thing. And so those are a markdown file is that I know, I believe in Copilot, it being a markdown file gives you like, heading like importance. I don't know if that's true. But it is being a markdown file do anything special or suggest markdown as a text file. For memories specifically? Yeah, yeah. Yeah, I don't I think all of these things make it more human readable is probably what's valuable. But I think to the AI, it doesn't matter if it's like markdown versus a bunch of bullet points. I think the AI is going to consume it like the same way. Yeah, it knows. All right, let's talk about if we're cooked or not. And this is something that we've been talking to a lot of people recently. And you seem to find people who are on one side where they're like, No, it makes mistakes. You know, and I think those people are kind of not totally understanding how good this stuff actually is, and how good it will be. And then on the flip side as well, you get these, these folks who have nothing in their GitHub and think that like, I'm never gonna write a line of code ever again. I'm somewhere in the middle. I've never argued against something I'm so excited for and in favor of in my life. Often people put me as like the anti AI guy on Twitter, which is hilarious, because I use it literally all day long. But I'm trying to just have some voice of reason here. But I'm curious, with the caveat of knowing that you guys have raised a bunch of money to do the next gen of dev with AI, what does the future of being a developer look like with AI? I think it's kind of like what you said. There's like, what does the internet like? The internet likes very polarizing thoughts, right? Like, no one, no one's cool for saying the thing that is like normie. So you're gonna have a bunch of Luddites that think AI is not going to be useful. Very clearly, that seems like a bad opinion to have, especially when a technology is getting so much better year over year. And then you have people that kind of like what you're saying, maybe they have a hatred towards developers, or largely speaking, they like to get clicks. And for them, they're like software development is done, right? You're going to get those two people and they'll get the most response. It's kind of exactly what you said. It's in between. I think that software development, maybe this is going to be the one hot take I have. I think a year or two from now, if you're not using a tool like Windsurf, I think you are just like significantly less productive as a developer. So I think what actually ends up happening is the number of developers does go up. And I'll tell you the crazy stat about this. When we launched Windsurf, before that, we had everyone at our company build an app using Windsurf. And they include our go-to-market team, salespeople that have never written a line of software. And instead of going out and buying these trivial tools, and I'm not saying expensive tools, to do basic things like quoting the pricing of our software, they actually went out and built the tool themselves. So for these very quick standalone apps, they're actually going out and building things. I'm not saying they're going to become what are the future of developers, but I think the aperture of what is possible for software development will grow in the next 10 years. And I think the number of developers will go up. But I think if a developer doesn't use these tools, they will be substantially less productive, I think is what's going to happen. And they will actually not be able to be competitive with developers, other developers out there. But I think the market is going to grow. I think it will grow tremendously. So you think it's going to grow. So what does software look like then? Because if we're thinking like, even yesterday, I needed to download every single episode of a podcast from an RSS feed and cache it and skip the download if I needed from my daughter, she wanted me to download it and put it on like her little music player.
> And I just typed in the little box what I wanted it to do and 200 lines of code, it worked first try. And I was just thinking like, that probably would have taken me two hours if it wasn't this. So like, if we're so much more productive, what does software look like? Are we just going to take Fridays off? Or like, are we gonna get paid less? Are just regular people going to be able to build this stuff for us? Okay, that's an interesting question. My viewpoint on this, for these simple kind of apps, I kind of feel like there's not gonna be a tremendous amount of like economic value that's gonna be there. There'll be a lot of personal value, but in terms of economic value, because this technology has become democratized, you're not gonna be able to sell that podcast downloader to a bunch of people for like thousands of dollars. It's effectively what happened. That market has just disappeared in some ways. But hey, like now you can do it for your own personal stuff way more efficiently and you don't need to go on Fiverr or whatever to go and build it. But I think here's my take on it for the companies, because that is where most developers are, ultimately speaking. Most developers are not hobbyists. They are people that work at companies. I don't look at it as, hey, like these companies are nice entities that are just gonna pay their developers the same amount and ask them to work less. No, actually like if you were to look at it from like a purely capitalist standpoint, they have a better return on investment now on investing in software. Their given dollar now is giving them more technology. Then the question becomes for this business, what is the ceiling of the amount of technology they can create and get value from? And I think for most companies that are large, there's a lot of technology that can be built to actually go in and optimize the business. I'll even give you a dumb example here. I think someone asked me a question. They were like, hey, what about a company like Safeway? You know, probably there's not much more they could do. And I think, hey, that's like maybe a lack of imagination. What happens if they went out and actually built robotics software that actually went out and did robotics within the store? There's a massive, massive ceiling on what technology can sort of drive. And I think if you go to every company and you ask them, what is all the technology you want to go out and build? It is such a long list that they basically don't even look at a lot of the stuff out there because they just know that they can't build it. So I actually think what happens in the short term, maybe you go to the full AGI thing. I don't particularly want to give a thought about like full AGI out there. But if you look at the medium term out there, these businesses are going to see there's an investment opportunity that has a higher return on investment, and they will go out and invest more in that opportunity. That's what the rational belief should be, if that makes sense. Yeah, it does. And you know, maybe, I don't know if you saw it going around the USPS website, their alert system is just somebody commenting and uncommenting different alerts out in an HTML file. So maybe websites like that will actually be able to build a real alert system at the end of the day because their developers will have to spend less time on it. But I've noticed that entirely with myself as well. I'm not having the editor replace me or the tools replace me. Right now, I'm able to accomplish flat out more things faster and less time. And we've seen it firsthand over here at Syntax. Our producer, Randy, he created a smile detection app by himself, and he's never made anything. So it's like, people can just make stuff. Like you said, it's the tools that you maybe would have made and sold and whatever. Yeah, that stuff is going away. You can't necessarily do that. But just the amount of things that we can create personally will increase the productivity like crazy on a personal level. And like the bar for features in software too. Like I use FreshBooks and they don't have AI categorization for my expenses. Like I had to click on every single expense and categorize it. And I'm like, I'm at a point now where I'm like, first of all, I built it myself because I just use the API. But like, I'm pissed that they don't have that feature. You could just, you can build that now. And now the bar for software. So like, I'm in this spot where I'm thinking like, the software will just get better, you know? It's not like we're just gonna sit down and twiddle our thumbs. We're like, well, we've built the CRUD apps now. Software is gonna keep getting better. We're gonna keep building stuff. Like we're hungry for apps that will do what it is that we want, so. The expectations will keep going up. It's like when you look at enterprise software from the early 2000s, it is hideous. It's like some Java swing stuff that you and I would never wanna touch anymore. Unless we were forced to and our company forced us to and we worked at a big company. And such a product is not gonna be able to get mainstream sort of adoption now. And that's a good thing, right? That's a good thing. What about larger code bases for this type of stuff? Because it's all fun to make a podcast downloader and whatnot, but like, let's say you open up like VS Code. That's a massive, massive project. How good is the AI at doing it right now with the sort of limitations of context windows? Quite good. We built Windsurf with Windsurf, right? So the first version that was available internally, everyone switched over and we started building new features using Windsurf and that's currently, you know, I've probably executed, I've opened four PRs this morning. Probably 50% of the code at least is written by Windsurf and at least it tells me what files to change, right? So if I'm gonna make a change that covers client server middleware, it's gonna tell me exactly where to go, if not write the code itself. And I think it just goes back to, it's not really about the context window anymore. It's not how many tokens you can kind of shove in at any given time. It's a bit more like what was the research done by the agent to figure out the steps needed to solve your feature or to create your feature or solve your problem. The agent is able to reason and brock through these like massive 100,000 line repositories like VS Code. Maybe to put it in concrete, like there's a architecture pattern in VS Code. So you have to create like an API that goes across different threads. And, you know, the VS Code team has thought a lot about this sort of thing. And, you know, we were kind of hopping in on their code base and trying to figure out, all right, if we wanted to add a button here, if we wanted to add a state variable here, how would we do that? You know, the agent is not gonna just ingest every single file that is relevant, but instead it's going to say, all right, I looked at this thread. This is what I kind of gained and learned about this particular part of the system. Now I need to go learn about system B, synthesize, summarize, understand. Now system C, and then it can kind of map reduce it to come back all three at one time and then decide, all right, I'm gonna make these changes. So it is able to accomplish quite a bit more. It's no longer capped by just simply how many tokens in you can put in. I think that's what's really cool about the way that the AI industry has moved. It's like not, it's becoming a bit more sophisticated, a bit way more powerful because of this shift. Yeah, maybe the intuition that Kevin just brought up is like, because you don't have just one shot where an LLM just outputs everything, it's not actually true that you need to pass the entire code base into the system, right? It's more similar to like, hey, when you solve a problem about a large code base and you maybe contribute something to Linux, you don't know everything about all of Linux, right? But if I asked you to explain your change and why you made it, you could probably do the explanation for that and your process of searching through the code base in less than 100,000 tokens, which is like 10,000 lines of code, right? You could explain that to me, hopefully, right? Unless it's like a mega complex PR, right? You could probably explain that to me. So basically once you say you don't have just like one shot at that and you can actually go and run code and you can surf through code and do a bunch of stuff, it actually changes, maybe flips the paradigm a little bit from what these early chat products were doing where all they were doing was talking about like ever larger context windows. Yeah. An example of this is maybe the unit test generation with kind of a one shot that you were talking about before, you have one chance to write the perfect unit test. Yeah. It would probably not live up to most people's expectations and certainly not in the largest enterprises, but now with the ability to actually execute said test to first think about test coverage, then run your code, then figure out what's going wrong and then maybe tweak some parts about the test, maybe tweak some parts about the actual source code. You have many more chances like Varun said to be at bat and figure out what's going wrong and how to make things better. And if you want to see all of the errors in your application, you'll want to check out Sentry at sentry.io forward slash syntax. You don't want a production application out there that, well, you have no visibility into in case something is blowing up and you might not even know it. So head on over to sentry.io forward slash syntax. Again, we've been using this tool for a long time and it totally rules. All right. So I know a big limitation of when libraries or platforms make a major change in their code base is that the AI tools all suddenly are giving you the last version of stuff. So like me personally, you know, Svelte 4 went to Svelte 5, they changed a whole bunch of stuff. Now, every single time I do anything in any AI system, I have to urge it several times. Please stop giving me this old syntax. How do you stay on top of those types of situations given where the LLMs are at? Yeah, I've got some thoughts here. I think there's a combination of like the recency of the data, not necessarily the training data, though model iterations and like training data getting updated is certainly part of the equation, but simply the ability to expose the web and expose like the most recent information. That's going to be a key part of this. And then the second interesting part that you mentioned, it sounds like your frustration is that you have to urge the AI to adhere to rules that you've told it many times, right? And even the youngest toddlers, hopefully, are reasonable at listening a second time. And I think that's where the concept of memory comes in. I think I might be a little optimistic. Yeah, yeah, I guess. Yeah.
> it's this kind of like marriage of those two ideas where, okay, if you're using a new library, a new version, like we're doing an internal upgrade to React 19. And we are internally using like web search to do this. And you'll just say, I'm using React 19. Now that's logged in memory automatically. That's not something that you have to put in the rules or yell it continuously every time you wanna send a message. But now it just kind of knows we're gonna use React 19. It's able to retrieve kind of the change log, the release notes and the breaking changes. And it'll recognize, okay, here's the differences that I need to have in order to approach what I'm doing right now. And in this way, it can kind of passively meet you where you want to be, as opposed to explicitly every single time telling it to do the same thing. I don't know if there's anything you wanna add onto that. No, I think that's huge. I think also the other pieces, because of the system being able to actually look at the code base, right? Not only at the code that exists, but at the packages, the dependencies, it actually just makes it more sophisticated in what it believes is the state of the code base. I don't think this, after doing that analysis, it'll think you want like an older version of Svelte, right, internally. But we also think there are more robust ways to get this rather than just the AI finding. Like I think what Kevin said with the idea of memories is a huge, huge sort of approach that we could take. Maybe one other interesting thing that you could talk about here is like the notion of like a trajectory, kind of understanding what someone has been doing. I'll give you an example. If you were to do an upgrade, right, you would start making changes. You might modify your package JSON to update the version number. Then you'll start actually ripping out certain functions and replacing the functionality. And what's really powerful about the fact that we now own the editor, and this is one of the reasons why I want to own the editor, the agent behaves very, very well when it knows your intent, right, as Varun mentioned before. And the way we understand and build up that intent is by looking at your recent actions. So if you are making a set of changes and there's a clear pattern in those changes, everything you do in Windsurf will now recognize that you're on this trajectory. We understand that you're doing the type of work that like the upgrade, for example. And so your next chat message, your next autocomplete, everything else will then take that into account going forward. So it's like this idea of like learning over time. Yeah, one of the cool properties about that is if you actually make a change in Windsurf to like one file and that actually is like the first to maybe 20 file changes, you can just tell Windsurf Cascade continue and it'll just go out and make the changes on the remainder because we are actually like passing in, we actually know at a granular level the changes that the user is making. And that's why like we think, you know, this notion of an agent is a term that is thrown out a lot, but I think the dream is actually the human and the AI are operating on the same version of where they think the software is going, right? It's not just like something that comes back to you with a bunch of code and vomits it out. It's like something that you had control over and we've tried to build this throughout the product. Switching a little bit, I just wanna talk about the design of Windsurf. It's obviously just the VS Code fork, but there's just like a little bit of je ne sais quoi added to it, you know? Like the command palette pops up in the middle, the tabs are a little bit different on the side. Is that something you plan on going a little bit more? Because it's kind of nice when the editor looks a little fresh. I'm glad you noticed these things. The team will be very happy to notice or to know that you noticed some of the things. I mean, we spent a decent amount of time thinking about like typography, for example. There's subtle changes in like the tabs that you noticed in the terminal. We did move the command palette to the center because we wanted to emphasize, we're treating it as almost like an everything bar type of pattern. So we made some like opinionated UX, UI decisions, some of which just to simply feel like something is new, something is fresh. And this is where, you know, maybe it doesn't offer any sort of performance gain or feature improvement, but it's part of the story that we're kind of creating something new. And when people want to, they wanna feel like they're using something new. And so that was part of the calculus there. And then there are some things that just simply demand a new pattern, right? If you're making a bunch of changes across a bunch of different files, you need some way to step through those files. So that's where the cascade action bar comes into play. Check, reject, all those sorts of things. And a lot of these are kind of, they're inspired by other products. And obviously we try and stick to sort of the VS code design because that's what people are used to. But we did give it a lot of thought to try and figure out, all right, what are the places that we wanna add a little bit of spice? Yeah, it's much appreciated. It's funny how, I always just want a little bit new. Like even changing my tabs to a custom font via like some CSS hacks is really nice. It just makes it feel fresh. It's fresh, yeah. Yeah, it's interesting for each of the new features, there's like a graveyard of like five that we like killed inside the company. But I think that's like the nature of how things go. Like, we launch everything internally to our developers and like, we are also very opinionated. But sometimes you get maybe an idea that a bunch of people may not have been completely on board with, but you just kind of go with it. Sometimes you need to be a little bold. And do you keep it like up to date with VS code? Like how does that work when you fork VS code, but you still want their updates? Yeah, it's a rather complex merge conflict. Maybe nightmare is too strong of a word. You can imagine we've made a decent number of changes to actually the core of VS code. And so when, you know, VS code releases version 1.9, we will be right there ready to merge that branch into ours and do this resolution so that we can figure out, all right, let's keep all the things that we've done, but also, you know, we should benefit from the great work that the VS code team does to just create a good ID platform. So it's ours, I would say. It's its main power. Do you use Windsurf for that? Yeah, yeah, yeah. Windsurf is very good at synthesizing this information, to be honest. You know, one of the interesting things, maybe a couple of examples of this and of other companies that do things like this are that are much harder, by the way. Significantly harder is, Google has their own version of Linux, right? And they're constantly like patching the Linux in as Linux new versions come in, they're constantly making changes. I think the difference for us in our space that's maybe a little true is, I don't know, a lot of the core functionality for VS code, I don't know if you feel this, but like what has really changed for you in the last year for pure VS code? Don't include other extensions, but just pure VS code. Yeah, it's all co-pilot stuff. It's nothing in the UI and Microsoft in particular has never excelled in the UI department. I mean, that was this big sacrifice coming from Adam editor beforehand was like, all right, you're going to VS code and it's not, it doesn't look as nice, but it does more, you know? So yeah, they've never really been tweaking too much around the general UI, not even aesthetically, but features wise as well, yeah. Which is why like the urgency for just everything that they have and a lot of stuff that they have is not ridiculously high. And we're like constantly on, you know, trying to see like, hey, are there meaningful things that they're doing? But I will say just in general, when it comes to like the co-pilot UI UX, I guess like we feel like a little bit opinionated on how that UI UX should be. So we're not like the most excited to take like the co-pilot UI UX that they have. I think like some of it, we would not do ourselves. So I guess like that's the way we sort of treat it, but it is like an exercise inside the company, but not something that other companies don't do for other large like open source projects. Totally. Do you guys have like a back channel of VS code, like a telegram group of people who have forked VS code? Cause I was thinking about it, I was like, there's probably a dozens of companies that have forked VS code. Maybe not dozens, but like there's several companies that are like code sandbox are running it online. And then there's several that are running it as desktop applications. And then there's several that are using it in their like product as like an editor, or maybe it's just Monaco. And I was like, man, there's gotta be some sort of like back channel group of people who are like, hey, has anyone ever dealt with this? We gotta make one. But interestingly, the craziest one, going back to Google, Google even has their own fork of VS code inside of Google. Really? Not IDX, but their own? My understanding is IDX is not being used internally. I mean, this is the classic thing of like how a lot of Google products, like they just put the same one that they're using internally. That's cool. I just like the future of AI. Do you think that there's going to be any like major leaps and bounds? The last couple of years have been nuts in terms of AI in general, not just coding, but the leaps and bounds we've seen, you know, like we went from ha ha, look at this thing, can't do a hand, can't write a word to, oh my gosh, they're making commercials with this. You're obviously in the space. Do you see that petering out or increasing? You know, I think the way we sort of think about it are what people do is they look at like ideas and are they tapering off? And I think one of the ideas that people thought were tapering off was this idea of pre-training. The idea of pre-training is we're going to make ever larger and larger models that have more and more compute. And that idea was petering off. And it makes sense that that idea, even if it doesn't peter off, can't grow like by a hundred X every year. You cannot build like a 50 times larger data center like every year. That would be very hard at some point, right? Cause it just from a power consumption standpoint, but human ingenuity is like very deep, right? And people want to solve this problem interestingly. And there are many axes to.
> to make these products better, right? Like using different types of tool, right? Multi-step ways of using the product. Even given the same model sizes unlocking a lot of new value add. You see people like OpenAI and probably many others will follow suit at this idea of like test and compute. What happens if you let the model think to itself? Granted, I think there's some trade-offs to that too. If I am not that excited about a model thinking it's to itself for 10 minutes and giving me a response, if it could have just ran some commands and then given it to me in like 10 seconds, right? Like I would rather prefer that outcome. But I guess maybe my point is there are so many axes by which these products can get better that we will basically see like exponential improvements because of each axis getting better. Like, okay, you'll see one axis of I let the model run for longer and it's smarter. Okay, people will get better at that. They will make it so that it doesn't need to run for as long and it'll get better. It'll get better at using arbitrary tools. It'll get better at using the context link that it already has. There will be a much more efficient way of using a lot more context. Right now to use context, most of the approaches use this approach called attention, right, which is a quadratic algorithm. So what that means is if you have a million tokens of context versus a billion, you are now plugging in a million times the amount of compute. So this answer probably doesn't sound clean, but the answer really is it's gonna be stacking up wins in a bunch of different stacks all the way down to NVIDIA, right? NVIDIA is now making their data center GPUs more efficient. And all of these approaches are gonna give us a different type of improvement, right? Ultimately, that is gonna feel like it is an exponential improvement year over year. Yeah, singular approaches may hit a wall, but then we will come up with new approaches internally. So I'm actually very optimistic about this. I'm not of the opinion of, hey, this approach cannot scale anymore. I think that just indicates to us that we don't have enough ingenuity to think of other ways to improve the models and products. Yeah, and even on top of that, it does still feel like super early days for interface in how we interface with these tools in general. I think we're all still learning how to interface with them and finding new inventive ways to do that. I mean, even was a co-pilot workspace. That's an entirely different way of handling PRs than any tool before it kind of was like, all right, we're gonna build this right into GitHub. And I think those types of approaches I think are only gonna continue to increase as we get more and more comfortable using these things. I totally agree with you. In fact, I think the best example of this is ChadGPT. I was actually talking to Sam at some point from OpenAI and asked him like, hey, why did it take so long for you guys to come out with, for the world to come out with ChadGPT given the fact that these instruction-based models had been things that Google and OpenAI had been noodling around with for over a year or two. And it's kind of just the right interface popped up, which is crazy to think about, right? It's crazy to think about. There's also just like this massive latent potential for these products that is just much more than just what the raw model capability is. But that's just software in general, right? In general, every piece of software is a wrapper around, you know, an AWS EC2 instance, right? So, and it's like up to people to figure out ways to build better software around that. Is there any stuff like in your labs that you just, like, is it part of the company that just tries wild things? Because like, yeah, we don't know what that next killer way of approaching this is. I think one of the mottos we have, and Kevin can talk about his team and some product work, is like, we should be failing probably over 50% of the things we do. Okay, that's not like some glorious statement for the company. I think it's like, you know, three things. I think we hire really great people at the company, but we are not omniscient, right? I don't think smart people have a monopoly over being right always. In fact, we were probably wrong a lot of the time. And I think if we are not wrong a lot, that probably means we're not trying enough ambitious things. We're doing things once they're too obvious, right? Or we're unwilling to change our mind on the ideas that are clearly bad, right? Which is an even worse thing. That spells imminent death to a startup. So I think we should be willing to do a lot of things and a lot of things to fail. Like we had, Cascade was built on top of research that we're doing inside the company for many, many quarters, but we just couldn't crack it to make it feel like a good enough product until very recently. Yeah, I think one of the big strengths of ours that Marin touched on earlier is that our internal team is incredibly skeptical. We are all technology optimists in the sense that we believe that technology is going to get better. We believe AI is going to get better, but we're incredibly skeptical about how these things actually fit into our lives, right? It's the, oh, this is something cool, but really, is it actually going to help me every day? And it's not until it really hits that threshold of, okay, I'm using this like multiple times a day that we really, okay, we're going to put this into production. We're going to start treating this with seriousness because like we were talking about, there's so many cool things and so many cool directions that you could take something, but you have to be very, very realistic about just how helpful it actually is versus kind of trendy or flashy. Yeah, I could imagine you could find something to be cool. You could fall in love with it and then just not realize, oh wait, nevermind, this isn't actually going to get picked up, yeah. Totally, totally. Can we talk about pricing? Because I know Kodium has been has free forever plan. I know there's a free version of Windsurf. And then I know you launched at 10 bucks, assuming nobody in the company has ever hit the limit. And then like within a week, there was people like blowing through it, using it like, it's amazing the power users go through it. So now it's 15 bucks a month. How does that break down? What does that get you? I could take it. Okay, so basically I think we have, there are many types of users that use the product, right? Some people actually are using the product who are extremely non-technical, right? For them, this is the only way that they interface with building applications. They don't even touch the IDE to write code, which is foreign to all of us in our company, right? That's foreign to us, right? Because they're building these apps and probably very quickly, sort of using them for what they want and maybe moving on to the next thing, right? And when we originally built the product, we had some number of credits we were willing to give. We should realize our average user uses significantly more than that number of credits. So we had to increase the price and we also doubled the number of credits. So compared to what we had before, right? So it is not a cheap product for us to run by any stretch of the imagination, but despite that people are also blowing through the amount of usage right now for the $15 product as well. In fact, like our usage is so high, we've hit rate limits at the highest of highest levels for like providers everywhere right now. I think like for us, we are not the type of company that really wants to take a lot of price. I know that that sounds like sketchy for a startup to roughly say, but the real reason is because we have like a real enterprise business. Like companies like JPMorgan Chase and Dell have thousands, close to 10 plus thousand developers using the product right now internally. And yeah, we even won like JPMorgan Chase's Hall of Innovation Award. And that's where we see the sort of real profitable revenue for the business coming from, right? Not from individual developers that really want to cut their teeth on AI tools. So there's like this fine line of like, we cannot go bankrupt giving our product away, but also at the same time, like we want to set like the lowest price possible that we can to get the most people using the product. I would also say we've kind of positioned ourselves in such a way where, you know, the cost of intelligence is getting cheaper and cheaper. And I think unanimously, like if you look across the board, all the different model providers, every model is just getting better. Every product is inheriting from that. And in the same way, like we are positioning ourselves to kind of benefit from the industry trends. So the quality will continue to go up. The cost will continue to go down. The speed will continue to get faster. And hopefully, you know, Windsurf will inherit from these things. And that's, those three axes are really what we're working around the clock to try and figure out. That's awesome. One more thing I want to ask about was this whole idea of like running it in the browser. Because it seemed like for a while that, and even like companies like Shopify, all their devs don't download an editor. You know, it's all cloud-based. You just go to a website, you log in, that's your whole editing experience for everything. And that cuts down on all their DevOps experience. I'm sure it's a big security thing, right? You can pull the plug and immediately if someone's fired, they don't have access to any of the code. It sort of changed now that we've got all these AI things. Will that ever be a thing with Windsurf and these editors where it will just run in the browser or run on like a thin client somewhere? We actually have no problem with that in the longterm to basically provide a way to run it in the browser. There's no real sort of detriment. One of the weird things that we sort of felt was, hey, if we need to make people download an app, maybe there would be some reluctance. I guess we were wrong. A lot of people are willing to download an app if they think the juice is worth the squeeze. And I guess one of the cool parts about the design of these kind of editors is they can connect to remote containers. So actually a lot of companies, what they ultimately do is they use the dev container model, right, with remote SSH. The idea is you are connecting to another machine. And if you do cut off access to that machine, you do lose access to the code. So look, if our users ultimately tell us, hey, we really, really want this product to run in the browser, we're happy to do that. But it comes at the cost of some iteration velocity for us in the short term. But products like the OSS version or code OSS, which is the base of VS Code, can run in the browser, but that's largely because they are built on top of, you know, Electron and all of these other primitives that make it easy to do so. Awesome. It kind of has a company. You got to be a little bit focused. There's going to be a lot of people asking for all sorts of things, right? We've all been kind of the recipient of users asking for features. Oh, yeah. The Windsurf came out like two months ago. And so we're going to be really,
> intentionally, you know, our team is growing. It's a cracked team, but you know, we only have so many people. And so we're trying to, we always have to be kind of ruthlessly prioritizing what to work on next. And, you know, at some point, maybe web is the place we want to extend to. But right now, we're pretty, pretty locked in on just the Windsurf. Yeah. And I appreciate that as well. Yes. You got to think like, rolling anything out in like VS Code standard, probably they have to think about every single possible person, every single type of developer, you know, like as Python developers are going to be okay with this feature, because it does X, Y, and Z, or what about when somebody doesn't have a sidebar available? Or what about when someone's popped out? There's so many different edge cases for that type of thing. And as soon as you start to say, okay, well, we'll also run it in the browser. And we'll also do this, then it gets slower to see new features and new improvements. And that's when a product starts to go. Yeah, yeah. Usually in this show, at the end, we do Sick Picks and Shameless Plugs. Kevin, you've given a Sick Pick and a Shameless Plug before. Would you both like to give a Sick Pick and Shameless Plug? I can go first. I've done this exercise before. On the train into work today, I was thinking about, I definitely have a Sick Pick recently. So as you two might know, I take a lot of photos. So I've recently treated myself to a new Sick Pick. It's called the Ricoh GR3X. It's a point and shoot, shoots raw, has film simulations and the whole thing. And I've recently been taking that all around where I go to kind of get the daily life, street view, film simulation type of look. And that's been a lot of fun for me. So that would be my Sick Pick. Something along that line. It doesn't have to be work related. Bruin only works. So, you know, it's hard to... Maybe this would have been a nice one if I had cycled as much. But I really like if I could get, be one of the cool kids that could get the automatic sort of gear changing mechanism, the Di2 on my cycle. That's a big one. Unfortunately, like I don't have one. So that's like the topic. That's a sick wish. That's a sick wish. I've seen those often where there's no, there's no cable from like the gear select to where the derailleur is. And I often think like, man, that's why. And I've seen guys change batteries out on them while they're like on tour to France. It's crazy as well. It's crazy. You don't need to change the, there's only one selector. So it automatically cycles between the big rig and the little rig automatically for you. It knows which one to sort of go on. And it's a smooth experience. The hard part of all these things is the charging. It just feels like I would just be worried about the charging the whole time. Like, when do I charge this? And bicycles right now, you don't need to worry about any of this stuff. I guess you do need to do routine maintenance and stuff like that. Sometimes. Yeah. I guess the battery introduction is always, I feel like there's that one person who at the start of the ride is like, shoot, I didn't charge my gears. And it's like, well... You're just screwed at that point. Yeah. Yeah. It doesn't just like fall back. I'm sure you could push it over. But that's crazy. I want to try this. I want to hack it. What is it? Is it Bluetooth? I'm curious what the technology is. Okay. Because I've been dipping into the web Bluetooth API recently, which... Oh, cool. It's your thing. It's my shameless work. Oh, yeah. I should windsurf it. Yeah. I wonder if it could. Because Chrome has a really good, like, about Bluetooth or something like that. And it will list all the devices that are within range. It's really cool because it will show you if there's air tags and stuff around you. Oh, interesting. Yeah. If you ever want to know, like, what Bluetooth devices are near me and not just, like, what the computer thinks you should see. Like, there's thousands of devices that are constantly sending out Bluetooth. Radiation. Yes, exactly. You can, like, locate these things, too, right? Because Bluetooth kind of helps you with location. Could you, like, just find where it is? Oh, man. Probably. It's all about, like, signal strength, right? Like, there's with the radios, there's a RSSI and there's another one. It'll tell you the signal of the radio. So, assuming, yeah, you can move around and as the signal gets higher or lower, you could beep it. So, maybe I'll try that. That feels like a very scary security risk, to just go to an airport and there's just someone doing this. Yes. Yeah, I wonder. The thing about it, about being able to access the stuff on the Bluetooth is some of Bluetooth devices have, like, standardized things, like, get temperature and whatnot, and they will publish what they are. But then a lot of them will just, like, they don't tell you what the calls are. So, you have to sort of guess or reverse engineer what the actual calls are. We have a new baby and he had this, like, foot monitor for a heart rate. I took that and hooked it up to the web and put it on my thumb and I could get my heart rate through the little, it's like a smart sock that tells you the baby's heart rate and temperature as they're sleeping. Oh, yeah. That's cool. I hooked it up. So, yeah. Anyways, shameless plug. Well, obviously, probably you'd like to shamelessly plug Windsurf? Yeah, I think that's where we spend most of our time, I would say. Yeah, I bet. You want to do the official shameless plug statement? Yeah, you guys should all use Windsurf. Win.surf. Quite the pitch. Yeah. Win.surf. That's actually a good domain. Did you have to buy that or was it available? You know, it's available, but everything has a price. It wasn't the friend.com price or whatever that was. We would have made the news. We have not paid the friend.com price. How much was that? Oh, that was an outrageous amount. Yeah. Oh, the friend.com. Yeah. How much was it? How much was win.surf? I want to know that, too. Probably. I mean, it was probably maybe two orders of magnitude cheaper, probably. The friend.com prices. It was $1.9 million. No, it was $1.8 million. Okay. Yeah. One of my favorite things to do is ask people, what's the story behind the domain name? And almost nobody ever wants to tell us a story. They're all clammed up behind it. Maybe sometimes the owner of the previous domain is just like, it was hard to reason about it. And it seems it's just a bad feeling overall, at the very end, potentially. It's true. Or often, I think people buy them under mask. I had somebody negotiate with me back and forth for a long time on a domain name, and I finally sold it to them. A week later, boom, they put it up for sale 10 times the price I sold it to them. And it was like, they knew it was worth more, but they had made a fake, a whole fake story and everything behind it. And I actually, I forget what it was. I don't know if they ended up selling it or not. Yeah, I hope they didn't. Yes, right. Cool. Well, thank you so much, Kevin and Varun for coming on. This was really fun, really interesting to learn all about it. Definitely going to, I've been using Windsurf, going to be continuing to check it out with all the new features you guys are releasing. Cool. Yeah. Thanks for having us, Scott, Wes. Hopefully, we'll see you in person at a conference, maybe soon. For sure. Oh, yeah. We'll be around. Definitely. All right. Peace. Take care, guys. Thank you. Bye.
